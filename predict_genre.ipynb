{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "023e6947-e012-4bbf-9ef9-9180cfe7fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model loaded successfully.\n",
      "Predicted genre: pop\n"
     ]
    }
   ],
   "source": [
    "# 本腳本使用訓練好的 PyTorch CNN 模型預測音頻檔案的音樂類型。\n",
    "# 可用在GUI幫助使用者預測音頻檔案的音樂類型。\n",
    "# 請確保已運行 'my_script.py' 以生成以下檔案：\n",
    "# - 'music_genre_cnn.pth'：訓練好的模型參數\n",
    "# - 'scaler.pkl'：特徵標準化器\n",
    "# - 'label_encoder.pkl'：類型標籤編碼器\n",
    "#\n",
    "# 使用說明：\n",
    "# 1. 安裝所需庫：\n",
    "#    pip install torch numpy librosa scikit-learn\n",
    "# 2. 在 main() 函數中更新 'audio_file' 為您想要預測的音頻檔案路徑。\n",
    "# 3. 在 Jupyter Notebook 單元格中運行本腳本。\n",
    "#\n",
    "# 注意事項：\n",
    "# - 音頻檔案支援 .au、.wav、.mp3 等格式，建議與 GTZAN 數據集的 .au 格式一致。\n",
    "# - 音頻長度需至少 3 秒，多個片段將預測並返回最常見的類型。\n",
    "# - 確保模型和預處理檔案位於工作目錄。\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# 定義音樂類型（必須與訓練腳本一致）\n",
    "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "# 定義 PyTorch CNN 模型（必須與訓練腳本一致）\n",
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        # 第一層：線性層、ReLU 激活、20% 丟棄率\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        # 第二層：線性層、ReLU 激活、20% 丟棄率\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        # 第三層：線性層、ReLU 激活、20% 丟棄率\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        # 第四層：線性層、ReLU 激活、20% 丟棄率\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        # 輸出層：映射到類型數量\n",
    "        self.output = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 前向傳播：依次通過各層\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# 提取音頻特徵的函數（與訓練腳本一致）\n",
    "def extract_features(file_path, segment_duration=3):\n",
    "    try:\n",
    "        # 加載音頻檔案，採樣率設為 22050 Hz\n",
    "        audio, sr = librosa.load(file_path, sr=22050)\n",
    "        # 計算每個片段的樣本數\n",
    "        samples_per_segment = int(segment_duration * sr)\n",
    "        # 計算片段數量\n",
    "        num_segments = int(len(audio) / samples_per_segment)\n",
    "        \n",
    "        features = []\n",
    "        for seg in range(num_segments):\n",
    "            # 提取當前片段的音頻數據\n",
    "            start_sample = samples_per_segment * seg\n",
    "            end_sample = start_sample + samples_per_segment\n",
    "            segment = audio[start_sample:end_sample]\n",
    "            \n",
    "            # 提取 20 個 MFCC 係數\n",
    "            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=20).mean(axis=1)\n",
    "            # 提取 12 個色度特徵\n",
    "            chroma = librosa.feature.chroma_stft(y=segment, sr=sr).mean(axis=1)\n",
    "            # 提取 7 個頻譜對比特徵\n",
    "            contrast = librosa.feature.spectral_contrast(y=segment, sr=sr).mean(axis=1)\n",
    "            # 提取頻譜質心\n",
    "            centroid = librosa.feature.spectral_centroid(y=segment, sr=sr).mean()\n",
    "            # 提取頻譜滾降\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=segment, sr=sr).mean()\n",
    "            # 提取零交叉率\n",
    "            zcr = librosa.feature.zero_crossing_rate(y=segment).mean()\n",
    "            \n",
    "            # 合併特徵為 42 維向量\n",
    "            feature_vector = np.concatenate([mfcc, chroma, contrast, [centroid, rolloff, zcr]])\n",
    "            features.append(feature_vector)\n",
    "        \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "# 預測單個音頻檔案類型的函數\n",
    "def predict_genre(file_path, model, scaler, label_encoder, device):\n",
    "    # 提取特徵\n",
    "    features = extract_features(file_path)\n",
    "    if not features:\n",
    "        return None\n",
    "    \n",
    "    # 轉為 NumPy 陣列\n",
    "    features = np.array(features)\n",
    "    \n",
    "    # 標準化特徵\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # 轉為 PyTorch 張量並移到指定設備\n",
    "    features_tensor = torch.FloatTensor(features_scaled).to(device)\n",
    "    \n",
    "    # 設置模型為評估模式\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        # 進行預測\n",
    "        outputs = model(features_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions = predicted.cpu().numpy()\n",
    "    \n",
    "    # 將預測標籤轉為類型名稱\n",
    "    genres = label_encoder.inverse_transform(predictions)\n",
    "    \n",
    "    # 返回最常見的類型\n",
    "    unique, counts = np.unique(genres, return_counts=True)\n",
    "    most_common_genre = unique[np.argmax(counts)]\n",
    "    return most_common_genre\n",
    "\n",
    "# 主函數\n",
    "def main():\n",
    "    # 指定音頻檔案路徑\n",
    "    # 請替換為您的音頻檔案路徑，例如 'your_music.au' 或 'path/to/your_music.mp3'\n",
    "    audio_file = 'gui_test_music/pop_test1.mp3'\n",
    "\n",
    "    # 檢查檔案是否存在\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"File {audio_file} does not exist. Please update the path.\")\n",
    "        return\n",
    "\n",
    "    # 設置設備（GPU 或 CPU）\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 加載標準化器和標籤編碼器\n",
    "    try:\n",
    "        with open('scaler.pkl', 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        with open('label_encoder.pkl', 'rb') as f:\n",
    "            label_encoder = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Scaler or LabelEncoder not found. Please train the model using 'my_script.py' first.\")\n",
    "        return\n",
    "\n",
    "    # 初始化模型\n",
    "    input_dim = 42  # 特徵數量（MFCC、色度等）\n",
    "    num_classes = len(GENRES)\n",
    "    model = MusicGenreCNN(input_dim, num_classes).to(device)\n",
    "\n",
    "    # 加載模型參數\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('music_genre_cnn.pth', map_location=device))\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model file 'music_genre_cnn.pth' not found. Please train the model first.\")\n",
    "        return\n",
    "\n",
    "    # 執行類型預測\n",
    "    predicted_genre = predict_genre(audio_file, model, scaler, label_encoder, device)\n",
    "    if predicted_genre:\n",
    "        print(f\"Predicted genre: {predicted_genre}\")\n",
    "    else:\n",
    "        print(\"Unable to predict genre due to processing error.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36914252-98bd-402e-96ee-4a8738d037f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
